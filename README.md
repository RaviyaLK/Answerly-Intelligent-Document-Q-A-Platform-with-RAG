ğŸ§  Intelligent Document Q&A Platform with RAG


ğŸ“˜ Overview
This project demonstrates a Retrieval-Augmented Generation (RAG) system that allows users to upload documents and ask questions, receiving contextually relevant answers powered by Large Language Models (LLMs).

ğŸš€ Features
Document upload and text extraction

Text chunking and embedding using sentence-transformers

Vector storage with FAISS

Question answering via Hugging Face Transformers

Backend API built with FastAPI

Frontend interface using Next.js

CI/CD pipeline with GitHub Actions

Deployment on AWS SageMaker (Free Tier)

Metadata storage in Snowflake (Free Trial)

ğŸ› ï¸ Tech Stack
Frontend: Next.js, Tailwind CSS

Backend: FastAPI, Python

LLM: Hugging Face Transformers

Embeddings: sentence-transformers

Vector Store: FAISS

CI/CD: GitHub Actions

Deployment: Docker, AWS SageMaker

Database: Snowflake